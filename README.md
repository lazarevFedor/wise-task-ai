# wise-task-ai

## О проекте
В рамках данной работы была поставлена и решена задача разработки интеллектуального чат-помощника для учебного сайта **Wise Task**.

Основной целью являлось создание системы, способной предоставлять точные, контекстно обоснованные и проверяемые ответы на основе заранее подготовленного корпуса учебных материалов.

Для достижения поставленной цели был выбран подход **Retrieval-Augmented Generation (RAG)**, сочетающий методы информационного поиска и генеративные возможности языковых моделей. Данный подход позволил обеспечить доступ к актуальным знаниям без необходимости переобучения модели, а также существенно снизить риск генерации недостоверной информации за счёт использования внешней базы знаний.

Разработанная система может быть использована как основа для дальнейших исследований и расширений, включая увеличение объёма базы знаний, улучшение механизмов оценки качества ответов и адаптацию под индивидуальные потребности пользователей.

## Описание реализованной системы
В проекте была реализована система для управления циклом взаимодействия с ИИ-помощником. 
Система представляет собой микросервисное приложение, которые впоследствии интегрируется в основную систему Wise Tasks.

Приложение состоит из следующих логических частей:

1. **Qdrant DB** -- векторная база знаний с релевантными документами про теорию графов и приложение _Wise Task_
2. **Qdrant Indexer** -- сервис, который преобразует имеющиеся документы в чанки и выполняет их загрузку в **Qdrant DB**
3. **Qdrant Ingest** -- сервис поиска релевантных документов в **Qdrant DB**
4. **Core Service** -- сервис-оркестратор, управляет потоком данных в системе, взаимодействует с другими сервисами и базами данных, собирая все необходимое для ответа пользователю и обработки обратной связи от него
5. **PostgreSQL Feedbacks** -- база данных для сбора обратной связи от пользователя о качестве ответа ИИ-помощника
6. **llama_cpp** -- сервис на базе библиотеки llama.cpp с развернутой языковой моделью и сервером для приема запросов на генерацию
7. **LLM Service** -- сервис для управления процессом генерации(построение промтов, настройка параметров, оценка метриками, оркестрация запросов на генерацию)

## Инструкция по интеграции системы

1. **Клонирование проекта**

- Клонирование репозитория
```bash
git clone https://github.com/lazarevFedor/wise-task-ai
```

- Скачать литературу по теории графов по [ссылке](https://drive.google.com/drive/folders/1pQblC4fGq6sjUuCr8gO19k_sn1DSO0IN) и поместить ее в директорию __wise-task-ai/Qdrant/latex_books__. 

2. **Настройка переменных окружения**

- Необходимо создать файл __.env__(```touch .env```) в корне проекта и настроить переменные окружения по образцу из файла __wise-task-ai/.env.example__  с учетом особенностей среды, в которую интегрируется помощник, и технических особенностей места, где система развертывается.
3. **Запуск**

Для запуска нужно запустить __Docker Engine__ и прописать следующие команды в корневой директории проекта:

- ```mkdir db_data``` - команда, используемая только при первом запуске

- ```make build``` - команда для запуска
4. **API-доукментация**

API-документация по доступным портам и запросам доступна по [ссылке](https://.postman.co/workspace/My-Workspace~5435c05b-0462-4127-8f19-b71cf68e75ba/collection/692f06f96deab71ed7ec2981?action=share&creator=43478788)
