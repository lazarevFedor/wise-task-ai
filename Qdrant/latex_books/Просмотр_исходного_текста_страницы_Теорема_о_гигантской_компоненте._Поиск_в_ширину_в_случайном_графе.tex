== Теорема о гигантской компоненте ==
Перед формулировкой основной теоремы данного раздела дадим определение некоторых понятий, которые будут использованы в дальнейшем, а также приведем необходимые далее утверждения.
{{Определение
|definition='''Простейший ветвящийся процесс.''' Пусть Z_1,\dotsc Z_n,\dotsc {{---}} независимые пуассоновские величиныhttps://ru.wikipedia.org/wiki/Распределение_Пуассона с одним и тем же [[Математическое ожидание случайной величины | математическим ожиданием]] \lambda. Положим
Y_0 = 1, Y_i = Y_{i - 1} + Z_i - 1. 
}}
Представлять себе описанный только что процесс можно так: в начальный момент времени есть одна активная частица. Затем она создает Z_1 \geq 0 (может быть достигнуто, так как величина Z_1 равна нулю с положительной вероятностью) активных потомков и перестает быть активной. На следующем шаге все повторяется: какая-то частица (порядок роли не играет) порождает Z_2 новых частиц, а сама перестает быть активной, и так далее. Данный процесс может как завершиться (частицы перестанут быть активными), так и продолжаться бесконечно.
Говоря в терминах данного выше определения, Y_i и Z_i {{---}} количество активных и порожденных частиц в момент времени t, соответственно.
{{Теорема
|id = th1
|about=1
|statement=Пусть \lambda \leq 1. Тогда с вероятностью 1 процесс Y_t вырождается, т.е. P(\exists t: Y_t = 0) = 1.
}}
{{Теорема
|id = th2
|about=2
|statement=Пусть \lambda \ge 1. Пусть \gamma \in (0, 1) {{---}} единственное решение уравнения 1 - \gamma = e^{-\lambda \gamma}. Тогда процесс Y_t вырождается с вероятностью 1 - \gamma, т.е. P(\exists t: Y_t \leq 0) = 1 - \gamma.
}}
{{Определение
|definition='''Ветвящийся процесс на случайном графе.''' Пусть Z_1,\dotsc Z_n,\dotsc {{---}} независимые пуассоновские величины с одним и тем же [[Математическое ожидание случайной величины | математическим ожиданием]] \lambda. Положим
Y_0 = 1, Y_i = Y_{i - 1} + Z_i - 1. 
}}
В произвольном графе G = (V,E) зафиксируем v_1 \in V. Пометим ее как активную, а все остальные вершины {{---}} нейтральными. Выберем среди нейтральных вершин всех соседей вершины v_1. После этого пометим вершину v_1 как неактивную , а смежных с ней {{---}} как активных, а все остальные вершины {{---}} нейтральными.

Снова зафиксируем какую-нибудь активную вершину v_2, и повторим процесс, не меняя статус остальных уже активных вершин.

Продолжая этот ветвящийся процесс, мы в конце концов получим лишь неактивные (образующие компоненту, содержащую v_1) и нейтральные вершины.
Данный процесс очень похож на [[Обход в ширину|поиск в ширину]], этим свойством мы воспользуемся позднее.

Обозначим число активных вершин в момент времени t через Y_t, число нейтральных вершин {{---}} через N_t, а число соседей вершины, которую собираемся пометить как неактивную, {{---}} через Z_t. Тогда Y_0 = 1,Y_t = Y_{t − 1} + Z_t − 1. Все введенные величины зависят от графа G и от последовательности выбираемых вершин v_1,\dotsc.

Если G посчитать случайным, то при любом выборе вершин v_1,\dotsc получатся случайные величины Y_t, N_t, Z_t на пространстве G(n, p).

=== Теорема о гигантской компоненте ===

{{Теорема
|about=о гигантской компоненте
|statement=Рассмотрим модель G(n, p). Пусть p = \dfrac{ c }{n}.
: Если c , то найдется такая константа \beta, зависящая от c, что а.п.н. (асимптотически почти наверное) размер каждой связной компоненты случайного графа не превосходит \beta \ln n.
: Если же c > 1, то найдется такая константа \gamma, зависящая от c, что а.п.н. в случайном графе есть ровно одна компонента размера \geq\gamma n. Размер остальных компонент не превосходит \beta \ln n.
|proof=
Приведем здесь идеиВведение в математическое моделирование транспортных потоков: Учебное пособие/Издание 2-е, испр. и доп. А. В. Гасников и др. Под ред. А. В. Гасникова.{{---}} М.: МЦНМО, 2013 {{---}} C.330-339 {{---}} ISBN 978-5-4439-0040-7, изложенные А.М. Райгородским, основанные на доказательствеKarp R. The transitive closure of a random digraph//Random structures and algorithms. 1990. V. 1. P. 73–94. Р. Карпа. Такой формат позволит понять основные идеи и логику рассуждений. Строгий вариант приведен в Алон Н., Спенсер Дж. Вероятностный метод. М.: Бином. Лаборатория знаний, 2007..

Здесь и далее: Binomial {{---}} биномиальное распределение. 

'''Случай c '''.

Положим t_0=[\beta \ln n], где \beta {{---}} константа, которая будет подобрана далее. Нам хочется доказать, что с большой вероятностью каждая из компонент случайного графа имеет размер, меньший или равный t_0.
Но размер компоненты {{---}} это момент вырождения процесса Y_t на случайном графе. Значит, интересующее нас утверждение можно записать в следующем виде: P_{n, p}(\exists v_1 : Y_{t_0} > 0) \rightarrow 0, n \rightarrow \infty
Поскольку P_{n, p}(\exists v_1 : Y_{t_0} > 0) \le nP_{n, p}(Y_{t_0} \ge 0), достаточно найти такое \beta, при котором P_{n, p}(Y_{t_0} > 0) = o\left(\frac{1}{n}\right).

: P_{n, p}(Y_{t_0} > 0) = P_{n, p}(\xi_{t_o} \geq t_0) \thickapprox P_{n, p}(Binomial(n, 1 - (1 - p)^{t_0}) \geq t_0) \thickapprox
: (с учетом асимптотики 1 - (1 - p)^{t_0} \thicksim pt_0) 
: \thickapprox P_{n, p}(Binomial(n, pt_0) \geq t_0) \thickapprox
: (с учетом центральной предельной теоремы) 
: \thickapprox \int\limits_{\frac{t_0 - npt_0}{\sqrt{npt_0(1 - pt_0)}}}^\infty \frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx.

Поскольку c , нижний предел интегрирования имеет порядок \sqrt{t_0}. Таким образом, весь интеграл не превосходит величины
e^{−\delta t_0}. Выберем \beta таким, чтобы e^{−\delta t_0} оказалось меньше, чем
e^{-2 \ln n} = \dfrac{1}{n^2}, и в случае c теорема доказана.

'''Случай c > 1'''.

В данном случае ветвящийся процесс на графе нужно «запускать» не один раз, а многократно. Только так удается доказать, что а.п.н. хотя
бы в одном запуске возникнет гигантская компонента. Подробности можно найти в , мы же лишь поясним, откуда в текущей ситуации появляется \gamma из формулировки [[#th2|теоремы 2]] и почему она совпадает с одноименной константой из той же теоремы.

Чтобы доказать, что есть гигантская компонента, необходимо, чтобы ветвящийся процесс на графе не вырождался даже
при t \thickapprox \gamma n, то есть:
P_{n, p}(Y_{t} \le 0)\rightarrow 0, t \thickapprox \gamma n, n \rightarrow \infty

Так как по условию p = \dfrac{ c }{n}, то при t \thicksim \alpha n выполнено:
 1 - (1 - p)^t \thicksim 1 - e^{-pt} \thicksim 1 - e^{-c\alpha}
Применим центральную предельную теорему к
P_{n, p}(Y_{t} \le 0)\thickapprox P_{n, p}(Binomial(n, 1 - e^{-c\alpha}) \le \alpha n).
Пределы интегрирования в данном случае: от -\infty до \dfrac{\alpha n - n(1 - e^{-c\alpha})}{\sqrt{n(1 - e^{-c\alpha})e^{-c\alpha}}}.

Если \alpha , то мы получим искомое стремление вероятности к нулю.

Если \alpha > 1 - e^{-c\alpha}, то вероятность, напротив, будет стремиться к единице. 
Таким образом, критическое значение \alpha, вплоть до которого есть именно стремление к нулю, {{---}} это решение уравнения \alpha = 1 - e^{-c\alpha} или, что равносильно, 1 - \alpha = e^{-c\alpha}. А это и есть уравнение из [[#th2|теоремы 2]], если заменить \lambda на c.
}}

== Обход случайного графа ==
Приведем ряд утверждений, которые будут использованы в дальнейшем. Их доказательство, а также более детальный рассказ можно найти здесьBlum A. Random Graphs // CS 598 Topics in Algorithms (UIUC), 2015. URL: https://www.cs.cmu.edu/~avrim/598/chap4only.pdf.
{{Лемма
|id=lemma1
|about=1
|statement=Пусть d > 1. Тогда вероятность p, что size(cc(v)) = O(\log n) (cc {{---}} компонента связности, содержащая v): p {{---}} константа.
|proof=Главная идея доказательства, которую мы будем использовать в дальнейшем {{---}} изменение алгоритма поиска в ширину таким образом, чтобы только что открытые вершины были выбраны из множества фиксированного размера. Такая модификация превращает поиск в ширину в ветвящийся процесс.
}}
{{Теорема
|id=th4
|about=4
|statement=Пусть p = \frac{d}{n}, d > 1. 

\begin{equation*}
 \begin{cases} 
 & \text{1) Найдутся такие \(c_1, c_2\) , что с \(p \leq \frac{1}{n}\)  \(\exists cc: size(cc) \in (c_1\log n; c_2n)\) ;} \\
 & \text{2) Число вершин в компонентах размера \(O(\ln n)\) а.п.н. $\leq cn, c 
}}

=== Поиск в ширину ===
Рассмотрим граф G(n, p). Проанализируем его структуру по мере роста p:
* p = 0: граф состоит только из изолированных вершин. С ростом p в нем появляются ребра, [[Отношение связности, компоненты связности|компоненты связности]] получающегося леса объединяются.
* p = o\left(\frac{1}{n}\right): граф а.п.н. является лесом;
* p = \frac{d}{n}: появляются циклы. При d размер каждой из компонент связности равен \Omega(\log n). Число компонент связности, содержащих только один цикл {{---}} константа, зависящая от n. Таким образом, граф состоит из леса и компонент, содержащих единственный цикл без компонент размера \Omega(\log n);
* p = \frac{1}{n}: начинает образовываться гигантская компонента. Этот процесс происходит в два этапа:
** p = \frac{1}{n}: возникают компоненты из n^{\frac{2}{3}} вершин, а.п.н. являющиеся деревьями;
** p = \frac{d}{n}, d > 1: появляется гигантская компонента размером, пропорциональным количеству вершин во всем графе;
* p \geq \frac{d}{n}: все неизолированные вершины оказываются в гигантской компоненте;
* p \geq \frac{\ln n}{2n}: в графе остаются только изолированные плюс гигантская компонента;
* p = \frac{\ln n}{n}: граф становится связным;
* p = \frac{1}{2}: \forall \varepsilon > 0\;\exists C\subseteq G,\quad C {{---}} клика : |C| = (2 - \varepsilon )\log n;

Чтобы вычислить размер компоненты связности, пройдемся с помощью [[Обход в ширину|поиска в ширину]] по ней, стартуя из произвольной вершины и переходя к очередной неисследованной вершине, только если ребро между ними существует (данный факт необходимо установить независимо от других ребер, с вероятностью p = \frac{d}{n}). Если ребро существует, пометим следующую вершину как "открытую". Алгоритм закончит свою работу (обойдет всю компоненту связности), когда множество неисследованных "открытых" вершин станет пустым.

=== Проблема поиска в ширину ===
[[Файл:Bfs_problem_on_random_graph.png|300px|thumb|left|Проблема поиска в ширину на случайном графе]]
На данном изображении представлены результаты работы поиска в ширину , начавшемся в вершине 1 на двух графах: в первом у всех ребер p = 1, во втором же факт существования ребра определялся по ходу работы алгоритма {{---}} ребра, отмеченные пунктиром, не существуют. Проблема возникает, когда алгоритм просто не доходит до каких-то ребер, не выясняя, существуют они или нет: находясь в вершине 2, алгоритм не делал запрос о ребре (2, 3), так как у этому моменту вершина 3 уже была исследована. Ребра, которые потенциально могли быть не изученными, помечены на рисунке точечным пунктиром.

=== Неоткрытые вершины ===
Будем считать шагом алгоритма поиска открытие новой вершины. После первых i шагов алгоритма, любая из вершин, кроме стартовой, может быть неоткрытой с вероятностью p = (1 - \frac{d}{n})^i. Пусть z_i {{---}} число вершин, открытых за первые i шагов алгоритма поиска. z_i распределены как Binomial(n − 1,1 − (1 - \frac{d}{n})^i).

== Вероятность исчезновения ==
=== От поиска в ширину к ветвящимся процессам ===
Пользуясь идеями, изложенными в доказательстве [[#lemma1|леммы 1]], перейдем от модифицированного поиска в ширину к ветвящемуся процессу. Этот процесс используется для генерации случайных деревьев, возможно, бесконечного размера.
{{Определение
|definition='''Вероятность исчезновения''' (extinction probability) {{---}} вероятность, того, что дерево ветвящегося процесса будет конечным (процесс завершится через конечное время).
}}
Рассмотрим натуральное случайное число y, обозначающее количество потомков у очередной исследованной вершины. Каждый раз это значение выбирается случайно и независимо.
Процесс построения дерева заканчивается, образуя конечное дерево, когда у каждой вершины построены все ее потомки. Данный процесс может продолжаться бесконечно. 
Пусть:
* y \thicksim Binomial(s = n−c_1\log n, \frac{d}{n}).
* p′ {{---}} вероятность того, что size(cc(v)) = O(\log n) в модифицированном поиске в ширину.
* q {{---}} вероятность окончания процесса.
Тогда q \geq p′, поскольку поиск в ширину, заканчивающийся с \le c_1\log n вершинами, приводит к окончанию построения дерева.

p_i = \binom{s}{i}(\frac{d}{n})^i(1 − \frac{d}{n})^{s − i} {{---}} вероятность, что y производит i потомков, а значит:
\sum_{i = 0..s}p_i = 1 и \sum_{i = 0..s}ip_i = E(y) = \frac{ds}{n} > 1.

Глубина дерева не меньше количества вершин, поэтому вероятность того, что процесс закончится с деревом глубины t, вычисляется по следующей формуле:
a_t = p_0 + \sum_{i = 1..s}p_ia^i_{t - 1}

=== Вычисление вероятности исчезновения ===
{{Лемма
|id=lemma2
|about=2
|statement=Пусть m > 1. Пусть q {{---}} единственный корень f(x) = x на [0, 1). Тогда f_j(x) = \lim_{j \to \infty}p(j) = q для x\in [0,1).
}}
{{Теорема
|about=5
|id=th5
|statement=Рассмотрим дерево, сгенерированное ветвящимся процессом. Пусть f(x) {{---}} производящая функция числа потомков каждой вершины, а k {{---}} ожидаемое количество потомков в каждой вершине. Тогда верно следующее:

\begin{equation*}
 \begin{cases}
 k \le 1 &\text{— \(\;\) вероятность исчезновения равна 1, если вероятность} \\ & \;\;\;\;\;\,\text{появления ровно одного ребенка равна \(1\) ;}\\
 k > 1 &\text{— \(\;\) вероятность исчезновения является }\\&\;\;\;\;\;\,\text{единственным решением \(f(x) = x,\; x \in [0, 1)\) ;}
 \end{cases}
\end{equation*}
.
}}
В данной статье нами рассматривается простой случай ветвящегося процесса, в котором распределение количества потомков одинаково для каждой вершины. 
Обозначим:
* q {{---}} вероятность исчезновения;
* y \thicksim Binomial(s = n−c_1\log n, \frac{d}{n}) {{---}} количество потомков у очередной исследованной вершины;
* p_i = \binom{s}{i}(\frac{d}{n})^i(1 − \frac{d}{n})^{s − i} {{---}} вероятность, что y производит i потомков.

Для того, чтобы вычислить вероятность исчезновения, воспользуемся [[Производящая функция|производящей функцией]]:
f(x) = \sum_{i = 0..\infty}p_ix^i, где p_i {{---}} вероятность того, что y = i

Так как q {{---}} вероятность конечности алгоритма, то, если у корневой вершины i потомков, построение каждого из поддеревьев должно завершиться, и это произойдет с вероятностью q^i: 
q = \sum_{i = 0..\infty}p_iq^i
Благодаря чему, q является корнем уравнения:
x = \sum_{i = 0..\infty}p_ix^i \Leftrightarrow f(x) = x
[[Файл:Extinction_probability_equation_root_random_graph.png|thumb|300px|right|Решение уравнения f(x)=x]]

Рассмотрим решение данного уравнения на [0; 1]. 
x = 1 {{---}} всегда решение данного уравнения, так как \sum_{i = 0..\infty}p_i1^i = \sum_{i = 0..\infty}p_i = 1 = x.
Введем обозначения: k {{---}} количество потомков вершины, а m = f'(1), тогда m = f'(1) = \sum_{i = 1..\infty}ip_i = E(k).
Кажется, что при m > 1 дерево будет расти вечно, так как каждая вершина в момент времени j должна иметь потомков, однако при p_0 > 0 с положительной вероятностью у корня может вообще не быть потомков. В исходном G(n,\frac{d}{n}) m играет роль d, ввиду того, что d = E(k).
Пользуясь [[#lemma2|леммой 2]] и [[#th5|теоремой 5]], можно доказать, что:
# m {{---}} вероятность исчезновения = 1;
# m = 1 \wedge p_1 = 1 {{---}} вероятность исчезновения = 0;
# m > 1 {{---}} вероятность исчезновения , но, если p_0 = 0, процесс не завершится, так как у каждой вершины найдется по крайней мере один потомок;
Подробное описание доказательства данного факта, а также самих утверждений можно найти здесь.

== Вывод ==
Используя результаты, полученные в предыдущей части, сделаем вывод о вероятности окончания работы поиска в ширину на случайном графе G(n, \frac{d}{n}). Рассчитав p_0 и p_1, можно сделать следующие выводы:

\begin{equation*}
 \begin{cases}
 d 1&\text{— \(\;\) вероятность исчезновения меньше единицы, но, если \(p_0 = 0\) , процесс не завершится, так как у каждой вершины}\\&\;\;\;\;\;\,\text{найдется по крайней мере один потомок;}\\
 \end{cases}
\end{equation*}

== См. также ==
* [[Случайная величина]]
* [[Случайные графы]]
* [[Обход в ширину]]
* [[Производящая функция]]

== Литература ==

[[Категория: Дискретная математика]]
[[Категория: Дискретная математика и алгоритмы]]
[[Категория: Обходы графов]]
[[Категория: Связность в графах]]